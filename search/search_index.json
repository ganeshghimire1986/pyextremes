{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pyextremes Extreme Value Analysis (EVA) in Python pyextremes is a Python library aimed at performing univariate Extreme Value Analysis ( EVA ) Features \u00b6 pyextremes provides tools necessary to perform a wide range of tasks required to perform univariate EVA , such as: extraction of extreme events from time series using methods such as Block Maxima ( BM ) or Peaks Over Threshold ( POT ) fitting continuous distributions, such as GEVD , GPD , or user-specified continous distributions to the extracted extreme events visualization of model inputs, results, and goodness-of-fit statistics estimation of extreme events of given probability or return period (e.g. 100-year event) and of corresponding confidence intervals tools assisting with model selection and tuning, such as selection of block size in BM and threshold in POT Framework provided by the pyextremes library is easy to use and requires minimum user input to get production-ready results. Its default parameters are configured in compliance with best industry standards and underlying models are heavily based in the Extreme Value theory. The largest source of inspiration for this library was the book \"An Introduction to Statistical Modeling of Extreme Values\" by Stuart Coles. In addition to the easy-to-use interface, the library provides interface to underlying tools which can be used to build custom models. All scipy continuous distributions are supported out-of-the-box. Custom distributions can be also provided by subclassing scipy.stats.rv_continuous . Any parameter of a distribution may be frozen to investigate degenerate models (e.g. GEVD -> Gumbel or GPD -> Exponential ). Multiple ways of fitting the continuous distributions to the data are supported: MLE (default model) - Maximum Likelihood Estimate, uses SciPy Emcee - Markov Chain Monte Calro, see Emcee package by Dan Foreman-Mackey Installation \u00b6 Get latest version from PyPI: pip install pyextremes Install with optional dependencies: pip install pyextremes [ full ] Get latest experimental build from GitHub: pip install \"git+https://github.com/georgebv/pyextremes.git#egg=pyextremes\" For Anaconda Python distributions: conda install -c conda-forge pyextremes Dependencies \u00b6 Package Description emcee fit models using the Markov Chain Monte Carlo method matplotlib produce figures numpy perform efficient operations with arrays pandas Series and DataFrame objects for model intput and output scipy statistical models and mathematic functions Optional Dependencies \u00b6 Optional dependencies can be installed using the full tag as shown above or manually: Package Description tqdm progress bar for slow processes License \u00b6 This project is licensed under the terms of the MIT license.","title":"pyextremes"},{"location":"#features","text":"pyextremes provides tools necessary to perform a wide range of tasks required to perform univariate EVA , such as: extraction of extreme events from time series using methods such as Block Maxima ( BM ) or Peaks Over Threshold ( POT ) fitting continuous distributions, such as GEVD , GPD , or user-specified continous distributions to the extracted extreme events visualization of model inputs, results, and goodness-of-fit statistics estimation of extreme events of given probability or return period (e.g. 100-year event) and of corresponding confidence intervals tools assisting with model selection and tuning, such as selection of block size in BM and threshold in POT Framework provided by the pyextremes library is easy to use and requires minimum user input to get production-ready results. Its default parameters are configured in compliance with best industry standards and underlying models are heavily based in the Extreme Value theory. The largest source of inspiration for this library was the book \"An Introduction to Statistical Modeling of Extreme Values\" by Stuart Coles. In addition to the easy-to-use interface, the library provides interface to underlying tools which can be used to build custom models. All scipy continuous distributions are supported out-of-the-box. Custom distributions can be also provided by subclassing scipy.stats.rv_continuous . Any parameter of a distribution may be frozen to investigate degenerate models (e.g. GEVD -> Gumbel or GPD -> Exponential ). Multiple ways of fitting the continuous distributions to the data are supported: MLE (default model) - Maximum Likelihood Estimate, uses SciPy Emcee - Markov Chain Monte Calro, see Emcee package by Dan Foreman-Mackey","title":"Features"},{"location":"#installation","text":"Get latest version from PyPI: pip install pyextremes Install with optional dependencies: pip install pyextremes [ full ] Get latest experimental build from GitHub: pip install \"git+https://github.com/georgebv/pyextremes.git#egg=pyextremes\" For Anaconda Python distributions: conda install -c conda-forge pyextremes","title":"Installation"},{"location":"#dependencies","text":"Package Description emcee fit models using the Markov Chain Monte Carlo method matplotlib produce figures numpy perform efficient operations with arrays pandas Series and DataFrame objects for model intput and output scipy statistical models and mathematic functions","title":"Dependencies"},{"location":"#optional-dependencies","text":"Optional dependencies can be installed using the full tag as shown above or manually: Package Description tqdm progress bar for slow processes","title":"Optional Dependencies"},{"location":"#license","text":"This project is licensed under the terms of the MIT license.","title":"License"},{"location":"quickstart/","text":"Read data \u00b6 Every pyextremes model starts with a pandas.Series (see pandas documentation ) object, which contains timeseries of the data you want to analyze. This example is based on water level data for \"The Battery\" station located in New York. Read data: 1 2 3 4 5 6 7 8 import pandas as pd series = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) Tip The battery_wl.csv file referenced above is used throughout many tutorials and examples for the pyextremes package. If you want to reproduce all steps shown here and get the same results, the file can be downloaded here . Clean up data \u00b6 In order for the analysis results to be meaningful, data needs to be pre-processed by the user. This may include removal of data gaps, detrending, interpolation, removal of outliers, etc. Let's clean up the data: Code 9 10 11 12 13 14 15 16 series = ( series . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1925\" ):] ) series = series - ( series . index . array - pd . to_datetime ( \"1992\" )) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 When printed print ( series . head ()) Date-Time (GMT) 1926-11-20 05:00:00 -0.411120 1926-11-20 06:00:00 -0.777120 1926-11-20 07:00:00 -1.051120 1926-11-20 08:00:00 -1.051121 1926-11-20 09:00:00 -0.808121 Name: Water Elevation [m NAVD88], dtype: float64 Note See this tutorial for more information on why these specific operations were done. Create model \u00b6 The primary interface to the pyextremes library is provided via the EVA class. This class is responsible for all major tasks outlined above and is created using a simple command: 17 18 19 from pyextremes import EVA model = EVA ( series ) Extract extreme values \u00b6 The first step of extreme value analysis is extraction of extreme values from the timeseries. This is done by using the get_extremes method of the EVA class. In this example extremes will be extracted using the BM method and 1-year block_size , which give us annual maxima series. Code 20 model . get_extremes ( method = \"BM\" , block_size = \"365.2425D\" ) When printed print ( model . extremes . head ()) Date-Time (GMT) 1927-02-20 16:00:00 1.670154 1927-12-05 10:00:00 1.432893 1929-04-16 19:00:00 1.409977 1930-08-23 01:00:00 1.202101 1931-03-08 17:00:00 1.529547 Name: Water Elevation [m NAVD88], dtype: float64 Visualize extreme events \u00b6 model . plot_extremes () Fit a model \u00b6 The next step is selecting a model and fitting to the extracted extreme events. What this means practically is that we need to find model parameters (such as shape, location and scale for GEVD or GPD ) that maximize or minimize some metric (likelihood) and give us the best fit possible. This is done by calling the fit_model method: 21 model . fit_model () Info By default, the fit_model method selects the best model applicable to extracted extremes using the Akaike Information Criterion (AIC). Calculate return values \u00b6 The final goal of most EVA 's is estimation of return values. The simplest way to do this is by using the get_summary method: 22 23 24 25 26 summary = model . get_summary ( return_period = [ 1 , 2 , 5 , 10 , 25 , 50 , 100 , 250 , 500 , 1000 ], alpha = 0.95 , n_samples = 1000 , ) Note By default return period size is set to one year, which is defined as the mean year from the Gregorian calendar ( 365.2425 days ). This means that a return period of 100 corresponds to a 100-year event. A different return period size can be specified using the return_period_size argument. A value of 30D (30 days) would mean that a return period of 12 corresponds to approximately one year. Print the results: print ( summary ) return value lower ci upper ci return period 1.0 0.802610 -0.270608 1.024385 2.0 1.409343 1.370929 1.452727 5.0 1.622565 1.540408 1.710116 10.0 1.803499 1.678816 1.955386 25.0 2.090267 1.851597 2.417670 50.0 2.354889 1.992022 2.906734 100.0 2.671313 2.145480 3.568418 250.0 3.188356 2.346609 4.856107 500.0 3.671580 2.517831 6.232830 1000.0 4.252220 2.702800 8.036243 Investigate model \u00b6 After model results are obtained, logical questions naturally arise - how good is the model, are the obtained results meaningful, and how confident can I be with the estimated return values. One way to do that is by visually inspecting the model: 27 model . plot_diagnostic ( alpha = 0.95 ) Recap \u00b6 Following this example you should be able to do the following: set up an EVA instance extract extreme events fit a model get results For more in-depth tutorials on features of pyextremes see the User Guide.","title":"Quick Start"},{"location":"quickstart/#read-data","text":"Every pyextremes model starts with a pandas.Series (see pandas documentation ) object, which contains timeseries of the data you want to analyze. This example is based on water level data for \"The Battery\" station located in New York. Read data: 1 2 3 4 5 6 7 8 import pandas as pd series = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) Tip The battery_wl.csv file referenced above is used throughout many tutorials and examples for the pyextremes package. If you want to reproduce all steps shown here and get the same results, the file can be downloaded here .","title":"Read data"},{"location":"quickstart/#clean-up-data","text":"In order for the analysis results to be meaningful, data needs to be pre-processed by the user. This may include removal of data gaps, detrending, interpolation, removal of outliers, etc. Let's clean up the data: Code 9 10 11 12 13 14 15 16 series = ( series . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1925\" ):] ) series = series - ( series . index . array - pd . to_datetime ( \"1992\" )) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 When printed print ( series . head ()) Date-Time (GMT) 1926-11-20 05:00:00 -0.411120 1926-11-20 06:00:00 -0.777120 1926-11-20 07:00:00 -1.051120 1926-11-20 08:00:00 -1.051121 1926-11-20 09:00:00 -0.808121 Name: Water Elevation [m NAVD88], dtype: float64 Note See this tutorial for more information on why these specific operations were done.","title":"Clean up data"},{"location":"quickstart/#create-model","text":"The primary interface to the pyextremes library is provided via the EVA class. This class is responsible for all major tasks outlined above and is created using a simple command: 17 18 19 from pyextremes import EVA model = EVA ( series )","title":"Create model"},{"location":"quickstart/#extract-extreme-values","text":"The first step of extreme value analysis is extraction of extreme values from the timeseries. This is done by using the get_extremes method of the EVA class. In this example extremes will be extracted using the BM method and 1-year block_size , which give us annual maxima series. Code 20 model . get_extremes ( method = \"BM\" , block_size = \"365.2425D\" ) When printed print ( model . extremes . head ()) Date-Time (GMT) 1927-02-20 16:00:00 1.670154 1927-12-05 10:00:00 1.432893 1929-04-16 19:00:00 1.409977 1930-08-23 01:00:00 1.202101 1931-03-08 17:00:00 1.529547 Name: Water Elevation [m NAVD88], dtype: float64","title":"Extract extreme values"},{"location":"quickstart/#visualize-extreme-events","text":"model . plot_extremes ()","title":"Visualize extreme events"},{"location":"quickstart/#fit-a-model","text":"The next step is selecting a model and fitting to the extracted extreme events. What this means practically is that we need to find model parameters (such as shape, location and scale for GEVD or GPD ) that maximize or minimize some metric (likelihood) and give us the best fit possible. This is done by calling the fit_model method: 21 model . fit_model () Info By default, the fit_model method selects the best model applicable to extracted extremes using the Akaike Information Criterion (AIC).","title":"Fit a model"},{"location":"quickstart/#calculate-return-values","text":"The final goal of most EVA 's is estimation of return values. The simplest way to do this is by using the get_summary method: 22 23 24 25 26 summary = model . get_summary ( return_period = [ 1 , 2 , 5 , 10 , 25 , 50 , 100 , 250 , 500 , 1000 ], alpha = 0.95 , n_samples = 1000 , ) Note By default return period size is set to one year, which is defined as the mean year from the Gregorian calendar ( 365.2425 days ). This means that a return period of 100 corresponds to a 100-year event. A different return period size can be specified using the return_period_size argument. A value of 30D (30 days) would mean that a return period of 12 corresponds to approximately one year. Print the results: print ( summary ) return value lower ci upper ci return period 1.0 0.802610 -0.270608 1.024385 2.0 1.409343 1.370929 1.452727 5.0 1.622565 1.540408 1.710116 10.0 1.803499 1.678816 1.955386 25.0 2.090267 1.851597 2.417670 50.0 2.354889 1.992022 2.906734 100.0 2.671313 2.145480 3.568418 250.0 3.188356 2.346609 4.856107 500.0 3.671580 2.517831 6.232830 1000.0 4.252220 2.702800 8.036243","title":"Calculate return values"},{"location":"quickstart/#investigate-model","text":"After model results are obtained, logical questions naturally arise - how good is the model, are the obtained results meaningful, and how confident can I be with the estimated return values. One way to do that is by visually inspecting the model: 27 model . plot_diagnostic ( alpha = 0.95 )","title":"Investigate model"},{"location":"quickstart/#recap","text":"Following this example you should be able to do the following: set up an EVA instance extract extreme events fit a model get results For more in-depth tutorials on features of pyextremes see the User Guide.","title":"Recap"},{"location":"includes/abbreviations/","text":"","title":"Abbreviations"},{"location":"user-guide/1-read-first/","text":"Disclaimer \u00b6 pyextremes was created to make the process of running EVA simpler and faster. While the project is built with reasonable defaults which produce good results in most cases, one should not rely on the model as a source of ground truth. It is always the responsibility of the user to understand the subject of analysis and to properly interpret the model outputs. Example A 1000-year wave height of 100 meters is not physical and is an artifact of the underlying statistical model. One should always be mindful of the actual process being modeled and remember that the model gives a proabilistic estimate of extreme values under the assumption that the selected model (e.g. GEVD or GPD ) correctly describes the underlying process (in this example, water waves). Tutorial Structure \u00b6 Each tutorial section covers a particular area of EVA , such as extreme value extraction, fitting a model, or summarizing and visualizing analysis results. pyextremes was built in a modular fashion where each of these components is implemented independently and can be used on its own. In order to make life easier a helper class EVA was created (located in pyextremes.eva.EVA ) which chains these components together to streamline the most common types of EVA workflows and to reduce the amount of code a user needs to write when performing analysis. When posstible, sections of this tutorial present two alternative ways to perform the same action: via EVA and via low-level functions which are using by EVA behind the scenes.","title":"Read First"},{"location":"user-guide/1-read-first/#disclaimer","text":"pyextremes was created to make the process of running EVA simpler and faster. While the project is built with reasonable defaults which produce good results in most cases, one should not rely on the model as a source of ground truth. It is always the responsibility of the user to understand the subject of analysis and to properly interpret the model outputs. Example A 1000-year wave height of 100 meters is not physical and is an artifact of the underlying statistical model. One should always be mindful of the actual process being modeled and remember that the model gives a proabilistic estimate of extreme values under the assumption that the selected model (e.g. GEVD or GPD ) correctly describes the underlying process (in this example, water waves).","title":"Disclaimer"},{"location":"user-guide/1-read-first/#tutorial-structure","text":"Each tutorial section covers a particular area of EVA , such as extreme value extraction, fitting a model, or summarizing and visualizing analysis results. pyextremes was built in a modular fashion where each of these components is implemented independently and can be used on its own. In order to make life easier a helper class EVA was created (located in pyextremes.eva.EVA ) which chains these components together to streamline the most common types of EVA workflows and to reduce the amount of code a user needs to write when performing analysis. When posstible, sections of this tutorial present two alternative ways to perform the same action: via EVA and via low-level functions which are using by EVA behind the scenes.","title":"Tutorial Structure"},{"location":"user-guide/10-selecting-distribution/","text":"GEVD and GPD, degeneracy, model comparison (AIC, likelihood ratio).","title":"10 selecting distribution"},{"location":"user-guide/11-return-values/","text":"Discrete return values and summary.","title":"11 return values"},{"location":"user-guide/12-confidence-intervals/","text":"","title":"12 confidence intervals"},{"location":"user-guide/13-visualization/","text":"Diagnostic and its components.","title":"13 visualization"},{"location":"user-guide/14-goodness-of-fit/","text":"Kolmogorov-Smirnov and other (WIP).","title":"14 goodness of fit"},{"location":"user-guide/2-extreme-value-types/","text":"Traditionally EVA recognizes two types of extreme values: Block maxima ( BM ) Peaks over threshold ( POT ) The BM and POT extreme values are used to apply a statistical model ( GEVD or GPD accordingly) to allow for estimation of extreme events of an arbitrary probability of exceedance (return period). Both of these extreme value types represent a valid path of performing EVA and neither of these is generally better than another. Info GEVD and GPD models used for BM and POT extreme value types accordingly have a common theoretical basis and should be treated as complementary models, not as either/or. More information about why only the GEVD and GPD models are recommended to be used is provided in subsequent sections of this tutorial. Block Maxima \u00b6 The Block Maxima extreme values are extracted by selecting a block size (typically 1 year, also the default in pyextremes), then partitioning time series of your signal into equal consequtive blocks of this size, and for each block getting single maximum value (thus, block maxima). The resulting BM time series are then used to model extreme value behavior using the GEVD model family. See figure below illustrating this concept: Peaks Over Threshold \u00b6 The Peaks Over Threshold extreme values are extracted by choosing a threshold and selecting values higher or lower (depends on which extreme process is analyzed) than the threshold value. The selected values are then declustered by specifying minimum distance between adjacent clusters (e.g. 24 hours, which means that the model assumes that clusters of exceedances separater by this distiance or larger are independent). Selection of threshold and declustering distance is not a trivial task and has a strong effect on the EVA results. pyextremes provides a series of tools which help with threshold selection, these are described further in this tutorial. See figure below illustrating POT extremes: Which Method to Use \u00b6 One of the most important concepts of EVA is convergenece. What this means practically is that different models and approaches (as long as they are correctly applied) should be converging to the same answer (within reasonable confidence limits). Because of this, we cannot say that one method is better than another. Therefore, for a thorough analysis, user is advised to investigate both routes to make sure that the final answer of the analysis provides a robust estimate. A general rule of thumb, which is based on years of author's (subjective) experience, when performing EVA is to do the following: Use BM with a reasonable block size to avoid capturing seasonality (read more in the next section) to get the first estimates and to see how the extremes behave. Generally, BM is a \"simpler\" and more stable model which requires very little input from the user. Use POT with a reasonable threshold and declustering parameters (read more in the next section) to investigate how stable the model is in the region of target exceedance probabilities (return periods) and to gain more confidence in your results. Attention User is strongly discouraged from \"playing\" with the model parameters until a desired answer is achieved. EVA is not about getting a perfect estimate and a lack of a definitive answer is an answer in itself - it signifies that underlying process may be not random (e.g. seasonality or some trends were not removed prior to performing EVA ), that the model is poorly behaved for the data, or that there is simply not enough data to provide an accurate answer for a given probability. This is typically reflected by wide confidence intervals showing that the answer has high uncertainty. For example, your 100-year wind speed may be 50 knots (seems reasonable, right?) but the 95% confidence interval shows 10 to 120 knot uncertainty range - this clearly indicates that, while your answer happened to appear reasonable , the model is telling you that you cannot make any good faith judgement about the 100-year extreme event when using this data and methodology.","title":"Extreme Value Types"},{"location":"user-guide/2-extreme-value-types/#block-maxima","text":"The Block Maxima extreme values are extracted by selecting a block size (typically 1 year, also the default in pyextremes), then partitioning time series of your signal into equal consequtive blocks of this size, and for each block getting single maximum value (thus, block maxima). The resulting BM time series are then used to model extreme value behavior using the GEVD model family. See figure below illustrating this concept:","title":"Block Maxima"},{"location":"user-guide/2-extreme-value-types/#peaks-over-threshold","text":"The Peaks Over Threshold extreme values are extracted by choosing a threshold and selecting values higher or lower (depends on which extreme process is analyzed) than the threshold value. The selected values are then declustered by specifying minimum distance between adjacent clusters (e.g. 24 hours, which means that the model assumes that clusters of exceedances separater by this distiance or larger are independent). Selection of threshold and declustering distance is not a trivial task and has a strong effect on the EVA results. pyextremes provides a series of tools which help with threshold selection, these are described further in this tutorial. See figure below illustrating POT extremes:","title":"Peaks Over Threshold"},{"location":"user-guide/2-extreme-value-types/#which-method-to-use","text":"One of the most important concepts of EVA is convergenece. What this means practically is that different models and approaches (as long as they are correctly applied) should be converging to the same answer (within reasonable confidence limits). Because of this, we cannot say that one method is better than another. Therefore, for a thorough analysis, user is advised to investigate both routes to make sure that the final answer of the analysis provides a robust estimate. A general rule of thumb, which is based on years of author's (subjective) experience, when performing EVA is to do the following: Use BM with a reasonable block size to avoid capturing seasonality (read more in the next section) to get the first estimates and to see how the extremes behave. Generally, BM is a \"simpler\" and more stable model which requires very little input from the user. Use POT with a reasonable threshold and declustering parameters (read more in the next section) to investigate how stable the model is in the region of target exceedance probabilities (return periods) and to gain more confidence in your results. Attention User is strongly discouraged from \"playing\" with the model parameters until a desired answer is achieved. EVA is not about getting a perfect estimate and a lack of a definitive answer is an answer in itself - it signifies that underlying process may be not random (e.g. seasonality or some trends were not removed prior to performing EVA ), that the model is poorly behaved for the data, or that there is simply not enough data to provide an accurate answer for a given probability. This is typically reflected by wide confidence intervals showing that the answer has high uncertainty. For example, your 100-year wind speed may be 50 knots (seems reasonable, right?) but the 95% confidence interval shows 10 to 120 knot uncertainty range - this clearly indicates that, while your answer happened to appear reasonable , the model is telling you that you cannot make any good faith judgement about the 100-year extreme event when using this data and methodology.","title":"Which Method to Use"},{"location":"user-guide/3-block-maxima/","text":"Block Maxima or Minima (BM) extreme values are extracted from time series by partitioning it into blocks (segments) of equal duration (e.g. 1 year) and locating maximum or minimum values within each block. Block maxima extreme values asymptotically follow the Generalized Extreme Value Distribution family, according to the Fisher\u2013Tippett\u2013Gnedenko theorem . This theorem demonstrates that the GEVD family is the only possible limit for the block maxima extreme values. Extracting Extremes \u00b6 As outlined in the Read First section of this documentation, there are multiple ways the same thing can be achieved in pyextremes . The BM extraction function can be accessed via: pyextremes.extremes.block_maxima.get_extremes_block_maxima - the lowest level pyextremes.get_extremes - general-purpose extreme value extraction function pyextremes.EVA.get_extremes - helper-class (extreme values are not returned by this function, but instead are set on the EVA instance in the .extremes attribute) The simplest way to extract extreme values using BM method is to use the default parameters of the get_extremes function: Standalone from pyextremes import get_extremes from pyextremes.plotting import plot_extremes extremes = get_extremes ( data , \"BM\" ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , ) Using EVA from pyextremes import EVA model = EVA ( data = data ) model . get_extremes ( \"BM\" ) model . plot_extremes () Note You can get the data variable referenced above by running the following code: data = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) data = ( data . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1980\" ): pd . to_datetime ( \"1995\" )] ) data = ( data - ( data . index . array - pd . to_datetime ( \"1992\" )) ) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 \"battery_wl.csv\" can be downloaded here . All figures shown in this tutorial section were generated using this jupyter notebook . The get_extremes function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted method - extreme value extraction method: \"BM\" for Block Maxima and \"POT\" for Peaks Over Threshold. extremes_type - extreme value type: \"high\" for maxima (default) and \"low\" for minima The following paramters are used only when method = \"BM\" : block_size - block size, by default \"365.2425D\" . Internally is converted using the pandas . to_timedelta function. errors - specifies what to do when a block is empty (has no values). \"raise\" (default) raises error, \"ignore\" skips such blocks (not recommended), and \"coerce\" sets values for such blocks as average of extreme values in other blocks. min_last_block - minimum data availability ratio (0 to 1) in the last block. If the last block is shorter than this ration (e.g. 0.25 corresponds to 3 months for a block size of 1 year) then it is not used to get extreme values. This argument is useful to avoid situations when the last block is very small. By default this is None , which means that last block is always used. If we specify all of these parameters then the function would look as: get_extremes ( ts = data , method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , errors = \"raise\" , min_last_block = None , ) Selecting Block Size \u00b6 Like with most choices in statistics, selection of block size involves making a trade-off between bias and variance: blocks that are too small mean that approximation by the limit model (GEVD) is likely to be poor, leading to bias in estimation and extrapolation; large blocks generate few block maxima/minima, leading to large estimation variance. Pragmatic considerations often lead to the adoption of blocks of length one year. (Coles, 2004) An important thing to consider is also the physical nature of investigated signal. Many meteorological events (e.g. snowfall, rain, waves) are seasonal and, therefore, selection of block sizes smaller than 1-year would result in significant bias due to blocks no longer being equivalent (e.g. summer blocks are nearly guaranteed to have no snow). We can specify different block size using the block_size argument. Using the same data as above but with a block size of 2 years we get: Standalone extremes = get_extremes ( ts = data , method = \"BM\" , block_size = pd . to_timedelta ( \"365.2425D\" ) * 2 , ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = pd . to_timedelta ( \"365.2425D\" ) * 2 , ) Using EVA model = EVA ( data = data ) model . get_extremes ( \"BM\" , block_size = pd . to_timedelta ( \"365.2425D\" ) * 2 ) model . plot_extremes () Block Minima \u00b6 Block minima is fully equivalent to block maxima in the way it is extracted. Block minima can be extracted by setting the extremes_type argument to \"low\" : Standalone extremes = get_extremes ( ts = data , method = \"BM\" , extremes_type = \"low\" , ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , ) Using EVA model = EVA ( data = data ) model . get_extremes ( \"BM\" , extremes_type = \"low\" ) model . plot_extremes () Tip The pyextremes.EVA class works identically for both maxima and minima series and properly reflects (rotates) the data to fit statistical distributions. This is true as long as the extremes_type argument is correctly specified. Warning When analyzing block minima be mindful of your data being censored. An example of this would be water level time series - water levels cannot go below the seabed and will, therefore, be censored by the seabed elevation. Such series would no longer follow the GEVD and any results of such analysis would be unerliable.","title":"Block Maxima"},{"location":"user-guide/3-block-maxima/#extracting-extremes","text":"As outlined in the Read First section of this documentation, there are multiple ways the same thing can be achieved in pyextremes . The BM extraction function can be accessed via: pyextremes.extremes.block_maxima.get_extremes_block_maxima - the lowest level pyextremes.get_extremes - general-purpose extreme value extraction function pyextremes.EVA.get_extremes - helper-class (extreme values are not returned by this function, but instead are set on the EVA instance in the .extremes attribute) The simplest way to extract extreme values using BM method is to use the default parameters of the get_extremes function: Standalone from pyextremes import get_extremes from pyextremes.plotting import plot_extremes extremes = get_extremes ( data , \"BM\" ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , ) Using EVA from pyextremes import EVA model = EVA ( data = data ) model . get_extremes ( \"BM\" ) model . plot_extremes () Note You can get the data variable referenced above by running the following code: data = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) data = ( data . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1980\" ): pd . to_datetime ( \"1995\" )] ) data = ( data - ( data . index . array - pd . to_datetime ( \"1992\" )) ) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 \"battery_wl.csv\" can be downloaded here . All figures shown in this tutorial section were generated using this jupyter notebook . The get_extremes function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted method - extreme value extraction method: \"BM\" for Block Maxima and \"POT\" for Peaks Over Threshold. extremes_type - extreme value type: \"high\" for maxima (default) and \"low\" for minima The following paramters are used only when method = \"BM\" : block_size - block size, by default \"365.2425D\" . Internally is converted using the pandas . to_timedelta function. errors - specifies what to do when a block is empty (has no values). \"raise\" (default) raises error, \"ignore\" skips such blocks (not recommended), and \"coerce\" sets values for such blocks as average of extreme values in other blocks. min_last_block - minimum data availability ratio (0 to 1) in the last block. If the last block is shorter than this ration (e.g. 0.25 corresponds to 3 months for a block size of 1 year) then it is not used to get extreme values. This argument is useful to avoid situations when the last block is very small. By default this is None , which means that last block is always used. If we specify all of these parameters then the function would look as: get_extremes ( ts = data , method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , errors = \"raise\" , min_last_block = None , )","title":"Extracting Extremes"},{"location":"user-guide/3-block-maxima/#selecting-block-size","text":"Like with most choices in statistics, selection of block size involves making a trade-off between bias and variance: blocks that are too small mean that approximation by the limit model (GEVD) is likely to be poor, leading to bias in estimation and extrapolation; large blocks generate few block maxima/minima, leading to large estimation variance. Pragmatic considerations often lead to the adoption of blocks of length one year. (Coles, 2004) An important thing to consider is also the physical nature of investigated signal. Many meteorological events (e.g. snowfall, rain, waves) are seasonal and, therefore, selection of block sizes smaller than 1-year would result in significant bias due to blocks no longer being equivalent (e.g. summer blocks are nearly guaranteed to have no snow). We can specify different block size using the block_size argument. Using the same data as above but with a block size of 2 years we get: Standalone extremes = get_extremes ( ts = data , method = \"BM\" , block_size = pd . to_timedelta ( \"365.2425D\" ) * 2 , ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = pd . to_timedelta ( \"365.2425D\" ) * 2 , ) Using EVA model = EVA ( data = data ) model . get_extremes ( \"BM\" , block_size = pd . to_timedelta ( \"365.2425D\" ) * 2 ) model . plot_extremes ()","title":"Selecting Block Size"},{"location":"user-guide/3-block-maxima/#block-minima","text":"Block minima is fully equivalent to block maxima in the way it is extracted. Block minima can be extracted by setting the extremes_type argument to \"low\" : Standalone extremes = get_extremes ( ts = data , method = \"BM\" , extremes_type = \"low\" , ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , ) Using EVA model = EVA ( data = data ) model . get_extremes ( \"BM\" , extremes_type = \"low\" ) model . plot_extremes () Tip The pyextremes.EVA class works identically for both maxima and minima series and properly reflects (rotates) the data to fit statistical distributions. This is true as long as the extremes_type argument is correctly specified. Warning When analyzing block minima be mindful of your data being censored. An example of this would be water level time series - water levels cannot go below the seabed and will, therefore, be censored by the seabed elevation. Such series would no longer follow the GEVD and any results of such analysis would be unerliable.","title":"Block Minima"},{"location":"user-guide/4-peaks-over-threshold/","text":"Peaks Over Threshold (POT) extreme values are extracted from time series by first generating a time series of exceedances by selecting values above (or below for extremes_type = \"low\" ) a certain threshold and then declustering the exceedance time series by identifying clusters separated by a given time period and then selecting only the highest (lowest) values within each cluster. Declustering is performed in order to ensure that these values are IID (independent and identically distributed) which is required for the corresponding limit distribution to be applicable. The POT extreme values asymptotically follow the Generalized Pareto Distribution famliy, according to the Pickands\u2013Balkema\u2013De Haan theorem . Extracting Extremes \u00b6 As outlined in the Read First section of this documentation, there are multiple ways the same thing can be achieved in pyextremes . The POT extraction function can be accessed via: pyextremes.extremes.peaks_over_threshold.get_extremes_peaks_over_threshold - the lowest level pyextremes.get_extremes - general-purpose extreme value extraction function pyextremes.EVA.get_extremes - helper-class (extreme values are not returned by this function, but instead are set on the EVA instance in the .extremes attribute) The simplest way to extract extreme values using BM method is to use the default parameters of the get_extremes function: Standalone from pyextremes import get_extremes from pyextremes.plotting import plot_extremes extremes = get_extremes ( data , \"POT\" , threshold = 0.5 , r = \"12H\" ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"POT\" , extremes_type = \"high\" , threshold = 0.5 , r = \"12H\" , ) Using EVA from pyextremes import EVA model = EVA ( data = data ) model . get_extremes ( \"POT\" , threshold = 0.5 , r = \"12H\" ) model . plot_extremes ( show_clusters = True ) Note You can get the data variable referenced above by running the following code: data = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) data = ( data . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1980/01/01\" ): pd . to_datetime ( \"1980/01/20\" )] ) data = ( data - ( data . index . array - pd . to_datetime ( \"1992\" )) ) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 \"battery_wl.csv\" can be downloaded here . All figures shown in this tutorial section were generated using this jupyter notebook . The get_extremes function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted method - extreme value extraction method: \"BM\" for Block Maxima and \"POT\" for Peaks Over Threshold. extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. The following paramters are used only when method = \"POT\" : threshold - threshold value. r - minimum time distance (window duration) between adjacent clusters. Used to decluster exceedances by locating clusters where all exceedances are separated by distances no more than r and then locating maximum or minimum (depends on extremes_type ) values within each cluster. By default r = \"24H\" (24 hours). If we specify all of these parameters then the function would look as: get_extremes ( ts = data , method = \"POT\" , extremes_type = \"high\" , threshold = 0.5 , r = \"12H\" , ) Declustering \u00b6 As described earlier, declustering is controlled using the r argument. The goal of declustering is to ensure that all extreme values are IID, which is a requirement for the GPD model to be valid. Shown below is an example of extremes extracted from the same data and using the same threshold as above, but with a larger r value: Standalone extremes = get_extremes ( data , \"POT\" , threshold = 0.5 , r = \"24H\" ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"POT\" , extremes_type = \"high\" , threshold = 0.5 , r = \"24H\" , ) Using EVA model = EVA ( data = data ) model . get_extremes ( \"POT\" , threshold = 0.5 , r = \"24H\" ) model . plot_extremes ( show_clusters = True ) Tip Declustering value of r = \"24H\" was selected as a default value because pyextremes was developed when working with meteorological phenomena - namely, storms. Extreme storm surge and waves are generally caused by a storm event which generally doesn't exceed 12-24 hours and, because of this, the assumption of 24-hour inter-cluster distance results in a reasonably good separation of independent storm events. User is advised to select this parameter based on the properties of studied phenomena. For example, extreme precipitation events in some regions of the world can last for more than several days and, because of this, the default value of 24 hours would not be adequate for such analysis. Peaks Below Threshold \u00b6 A special case of Peaks Over Threshold is when instead of selecting values above the threshold we select values below it. Such values can be extracted by setting the extremes_type argument to \"low\" : Standalone extremes = get_extremes ( data , \"POT\" , threshold = 0.5 , r = \"24H\" , extremes_type = \"low\" , ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"POT\" , extremes_type = \"low\" , threshold = 0.5 , r = \"24H\" , ) Using EVA model = EVA ( data = data ) model . get_extremes ( \"POT\" , threshold = 0.5 , r = \"24H\" , extremes_type = \"low\" ) model . plot_extremes ( show_clusters = True ) Tip The pyextremes.EVA class works identically for both peaks over and below threshold series and properly reflects (rotates) the data to fit statistical distributions. This is true as long as the extremes_type argument is correctly specified. Warning When analyzing POT with extremes_type = \"low\" be mindful of your data being censored. An example of this would be water level time series - water levels cannot go below the seabed and will, therefore, be censored by the seabed elevation. Such series would no longer follow the GPD and any results of such analysis would be unerliable.","title":"Peaks Over Threshold"},{"location":"user-guide/4-peaks-over-threshold/#extracting-extremes","text":"As outlined in the Read First section of this documentation, there are multiple ways the same thing can be achieved in pyextremes . The POT extraction function can be accessed via: pyextremes.extremes.peaks_over_threshold.get_extremes_peaks_over_threshold - the lowest level pyextremes.get_extremes - general-purpose extreme value extraction function pyextremes.EVA.get_extremes - helper-class (extreme values are not returned by this function, but instead are set on the EVA instance in the .extremes attribute) The simplest way to extract extreme values using BM method is to use the default parameters of the get_extremes function: Standalone from pyextremes import get_extremes from pyextremes.plotting import plot_extremes extremes = get_extremes ( data , \"POT\" , threshold = 0.5 , r = \"12H\" ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"POT\" , extremes_type = \"high\" , threshold = 0.5 , r = \"12H\" , ) Using EVA from pyextremes import EVA model = EVA ( data = data ) model . get_extremes ( \"POT\" , threshold = 0.5 , r = \"12H\" ) model . plot_extremes ( show_clusters = True ) Note You can get the data variable referenced above by running the following code: data = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) data = ( data . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1980/01/01\" ): pd . to_datetime ( \"1980/01/20\" )] ) data = ( data - ( data . index . array - pd . to_datetime ( \"1992\" )) ) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 \"battery_wl.csv\" can be downloaded here . All figures shown in this tutorial section were generated using this jupyter notebook . The get_extremes function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted method - extreme value extraction method: \"BM\" for Block Maxima and \"POT\" for Peaks Over Threshold. extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. The following paramters are used only when method = \"POT\" : threshold - threshold value. r - minimum time distance (window duration) between adjacent clusters. Used to decluster exceedances by locating clusters where all exceedances are separated by distances no more than r and then locating maximum or minimum (depends on extremes_type ) values within each cluster. By default r = \"24H\" (24 hours). If we specify all of these parameters then the function would look as: get_extremes ( ts = data , method = \"POT\" , extremes_type = \"high\" , threshold = 0.5 , r = \"12H\" , )","title":"Extracting Extremes"},{"location":"user-guide/4-peaks-over-threshold/#declustering","text":"As described earlier, declustering is controlled using the r argument. The goal of declustering is to ensure that all extreme values are IID, which is a requirement for the GPD model to be valid. Shown below is an example of extremes extracted from the same data and using the same threshold as above, but with a larger r value: Standalone extremes = get_extremes ( data , \"POT\" , threshold = 0.5 , r = \"24H\" ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"POT\" , extremes_type = \"high\" , threshold = 0.5 , r = \"24H\" , ) Using EVA model = EVA ( data = data ) model . get_extremes ( \"POT\" , threshold = 0.5 , r = \"24H\" ) model . plot_extremes ( show_clusters = True ) Tip Declustering value of r = \"24H\" was selected as a default value because pyextremes was developed when working with meteorological phenomena - namely, storms. Extreme storm surge and waves are generally caused by a storm event which generally doesn't exceed 12-24 hours and, because of this, the assumption of 24-hour inter-cluster distance results in a reasonably good separation of independent storm events. User is advised to select this parameter based on the properties of studied phenomena. For example, extreme precipitation events in some regions of the world can last for more than several days and, because of this, the default value of 24 hours would not be adequate for such analysis.","title":"Declustering"},{"location":"user-guide/4-peaks-over-threshold/#peaks-below-threshold","text":"A special case of Peaks Over Threshold is when instead of selecting values above the threshold we select values below it. Such values can be extracted by setting the extremes_type argument to \"low\" : Standalone extremes = get_extremes ( data , \"POT\" , threshold = 0.5 , r = \"24H\" , extremes_type = \"low\" , ) plot_extremes ( ts = data , extremes = extremes , extremes_method = \"POT\" , extremes_type = \"low\" , threshold = 0.5 , r = \"24H\" , ) Using EVA model = EVA ( data = data ) model . get_extremes ( \"POT\" , threshold = 0.5 , r = \"24H\" , extremes_type = \"low\" ) model . plot_extremes ( show_clusters = True ) Tip The pyextremes.EVA class works identically for both peaks over and below threshold series and properly reflects (rotates) the data to fit statistical distributions. This is true as long as the extremes_type argument is correctly specified. Warning When analyzing POT with extremes_type = \"low\" be mindful of your data being censored. An example of this would be water level time series - water levels cannot go below the seabed and will, therefore, be censored by the seabed elevation. Such series would no longer follow the GPD and any results of such analysis would be unerliable.","title":"Peaks Below Threshold"},{"location":"user-guide/5-threshold-selection/","text":"Selection of the threshold value is a very important step because it has the strongest effect on the results of EVA. The core idea of threshold selection is the same as when selecting block size in the Block Maxima approach - it is a trade-off between bias and variance. Larger threshold values produce few extreme values and lead to large variance in result (confidence bounds), while smaller threshold values generate a sample which poorly approximates the GPD model. The opposite is true when performing EVA for extreme low values ( extremes_type = \"low\" ). The key goal of threshold selection can, therefore, be formulated as follows: Goal of threshold selection Select the smallest threshold value among those which produce extreme values following the limit exceedance model (Generalized Pareto Distribution family). Warning Threshold selection is probably the hardest part of Extreme Value Analysis when analyzing extreme values obtained using the Peaks Over Threshold method. It involves a great deal of subjective judgement and should be performed in conjunction with other methods, such as Block Maxima + GEVD, to gain more confidence in the validty of obtained results. Mean Residual Life \u00b6 Mean residual life plot plots average excess value over given threshold for a series of thresholds. The idea is that the mean residual life plot should be approximately linear above a threshold for which the Generalized Pareto Distribution model is valid. from pyextremes import plot_mean_residual_life plot_mean_residual_life ( data ) Note You can get the data variable referenced above by running the following code: data = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) data = ( data . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1925\" ):] ) data = ( data - ( data . index . array - pd . to_datetime ( \"1992\" )) ) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 \"battery_wl.csv\" can be downloaded here . All figures shown in this tutorial section were generated using this jupyter notebook . As seen in the figure above, exceedance values are approximately linear between threshold values of 1.2 and 1.8. This provides a range of threshold values which can be further investigated using other methods. The plot_mean_residual_life function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted thresholds - array of threshold for which the plot is displayed. By default 100 equally-spaced thresholds between 90th (10th if extremes_type = \"high\" ) percentile and 10th largest (smallest if extremes_type = \"low\" ) value in the series. extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. alpha - confidence interval width in the range (0, 1), by default it is 0.95. If None, then confidence interval is not shown. ax - matplotlib Axes object. If provided, then the plot is drawn on this axes. If None (default), new figure and axes are created figsize - figure size in inches in format (width, height). By default it is (8, 5). Note In author's (subjective) opinion this is the least useful technique among those listed in this section because mean residual life plots are very hard to interpret. Parameter Stability \u00b6 Parameter stability plot shows how shape and modified scale parameters of the Generalized Pareto Distribution change over a range of threshold values. The idea is that these parameters should be stable (vary by small amount) within a range of valid thresholds. from pyextremes import plot_parameter_stability plot_parameter_stability ( data ) As seen in the figure above, these parameters appear to stabilize around threshold value of 1.2 with subsequent values having higher variance due to smaller number of exceedances. The plot_parameter_stability function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted thresholds - array of threshold for which the plot is displayed. By default 100 equally-spaced thresholds between 90th (10th if extremes_type = \"high\" ) percentile and 10th largest (smallest if extremes_type = \"low\" ) value in the series. r - minimum time distance (window duration) between adjacent clusters. Used to decluster exceedances by locating clusters where all exceedances are separated by distances no more than r and then locating maximum or minimum (depends on extremes_type ) values within each cluster. By default r = \"24H\" (24 hours). extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. alpha - confidence interval width in the range (0, 1), by default it is 0.95. If None, then confidence interval is not shown. n_samples - number of bootstrap samples used to estimate confidence interval bounds (default=100). Ignored if alpha is None. axes - tuple with matplotlib Axes (ax_shape, ax_scale) for shape and scale values. If None (default), new figure and axes are created. figsize - figure size in inches in format (width, height). By default it is (8, 5). progress - if True, shows tqdm progress bar. By default False. Requires tqdm package. Return Value Stability \u00b6 An extension of the previous technique is to investigate stability of a target return value with a pre-defined return period over a range of thresholds. This technique provides a more intuitive metric of model stability. Let's plot it for the range of thresholds identified earlier: from pyextremes import plot_return_value_stability plot_return_value_stability ( data , return_period = 100 , thresholds = np . linspace ( 1.2 , 1.8 , 20 ), alpha = 0.95 , ) As seen in the figure above, the model is very stable for threshold values above 1.4. The plot_return_value_stability function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted return_period - return period given as a multiple of return_period_size . return_period_size - size of return period. Same as the r argument. By default this is 1 year. thresholds - array of threshold for which the plot is displayed. By default 100 equally-spaced thresholds between 90th (10th if extremes_type = \"high\" ) percentile and 10th largest (smallest if extremes_type = \"low\" ) value in the series. r - minimum time distance (window duration) between adjacent clusters. Used to decluster exceedances by locating clusters where all exceedances are separated by distances no more than r and then locating maximum or minimum (depends on extremes_type ) values within each cluster. By default r = \"24H\" (24 hours). extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. distributions - list of distributions for which the plot is produced. By default these are \"genpareto\" and \"expon\". A distribution must be either a name of distribution from scipy.stats or a subclass of scipy.stats.rv_continuous. See scipy.stats documentation alpha - confidence interval width in the range (0, 1), by default it is 0.95. If None, then confidence interval is not shown. n_samples - number of bootstrap samples used to estimate confidence interval bounds (default=100). Ignored if alpha is None. ax - matplotlib Axes object. If provided, then the plot is drawn on this axes. If None (default), new figure and axes are created figsize - figure size in inches in format (width, height). By default it is (8, 5). progress - if True, shows tqdm progress bar. By default False. Requires tqdm package. Warning This is the most dangerous threshold selection teqchnique presented in this section. It can be abused by selecting a threshold value which gives a desired result. Results of such analysis would be biased and invalid. Analyst should honestly present results of their analysis and high variance in answer should be considered a valuable result as well - it indicates that available data cann be used to obtain reliable results and that there is high uncertainty in the analyzed process. Putting it all Together \u00b6 pyextremes provides a convenience function to put all of the above together. It also adds an additional plot - AIC curve indicating relative model performance. The AIC curve should not be used as a threshold selection tool because it will always have the same logarithmic shape. Instead, it should guide the user as to which model (e.g. GEVD or Exponential) should be preferred for a given threshold. from pyextremes import plot_threshold_stability plot_threshold_stability ( data , return_period = 100 , thresholds = np . linspace ( 1.2 , 1.8 , 20 ), ) Based on the figures shown earlier, one may conclude that the valid threshold may lie between 1.4 and 1.6. A decision was made to select threshold value of 1.5. The plot_threshold_stability function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted return_period - return period given as a multiple of return_period_size . return_period_size - size of return period. Same as the r argument. By default this is 1 year. thresholds - array of threshold for which the plot is displayed. By default 100 equally-spaced thresholds between 90th (10th if extremes_type = \"high\" ) percentile and 10th largest (smallest if extremes_type = \"low\" ) value in the series. r - minimum time distance (window duration) between adjacent clusters. Used to decluster exceedances by locating clusters where all exceedances are separated by distances no more than r and then locating maximum or minimum (depends on extremes_type ) values within each cluster. By default r = \"24H\" (24 hours). extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. distributions - list of distributions for which the plot is produced. By default these are \"genpareto\" and \"expon\". A distribution must be either a name of distribution from scipy.stats or a subclass of scipy.stats.rv_continuous. See scipy.stats documentation alpha - confidence interval width in the range (0, 1), by default it is 0.95. If None, then confidence interval is not shown. n_samples - number of bootstrap samples used to estimate confidence interval bounds (default=100). Ignored if alpha is None. ax - matplotlib Axes object. If provided, then the plot is drawn on this axes. If None (default), new figure and axes are created figsize - figure size in inches in format (width, height). By default it is (8, 5). progress - if True, shows tqdm progress bar. By default False. Requires tqdm package. Results of selecting the threshold value 1.5 are shown below:","title":"Threshold Selection"},{"location":"user-guide/5-threshold-selection/#mean-residual-life","text":"Mean residual life plot plots average excess value over given threshold for a series of thresholds. The idea is that the mean residual life plot should be approximately linear above a threshold for which the Generalized Pareto Distribution model is valid. from pyextremes import plot_mean_residual_life plot_mean_residual_life ( data ) Note You can get the data variable referenced above by running the following code: data = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) data = ( data . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1925\" ):] ) data = ( data - ( data . index . array - pd . to_datetime ( \"1992\" )) ) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 \"battery_wl.csv\" can be downloaded here . All figures shown in this tutorial section were generated using this jupyter notebook . As seen in the figure above, exceedance values are approximately linear between threshold values of 1.2 and 1.8. This provides a range of threshold values which can be further investigated using other methods. The plot_mean_residual_life function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted thresholds - array of threshold for which the plot is displayed. By default 100 equally-spaced thresholds between 90th (10th if extremes_type = \"high\" ) percentile and 10th largest (smallest if extremes_type = \"low\" ) value in the series. extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. alpha - confidence interval width in the range (0, 1), by default it is 0.95. If None, then confidence interval is not shown. ax - matplotlib Axes object. If provided, then the plot is drawn on this axes. If None (default), new figure and axes are created figsize - figure size in inches in format (width, height). By default it is (8, 5). Note In author's (subjective) opinion this is the least useful technique among those listed in this section because mean residual life plots are very hard to interpret.","title":"Mean Residual Life"},{"location":"user-guide/5-threshold-selection/#parameter-stability","text":"Parameter stability plot shows how shape and modified scale parameters of the Generalized Pareto Distribution change over a range of threshold values. The idea is that these parameters should be stable (vary by small amount) within a range of valid thresholds. from pyextremes import plot_parameter_stability plot_parameter_stability ( data ) As seen in the figure above, these parameters appear to stabilize around threshold value of 1.2 with subsequent values having higher variance due to smaller number of exceedances. The plot_parameter_stability function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted thresholds - array of threshold for which the plot is displayed. By default 100 equally-spaced thresholds between 90th (10th if extremes_type = \"high\" ) percentile and 10th largest (smallest if extremes_type = \"low\" ) value in the series. r - minimum time distance (window duration) between adjacent clusters. Used to decluster exceedances by locating clusters where all exceedances are separated by distances no more than r and then locating maximum or minimum (depends on extremes_type ) values within each cluster. By default r = \"24H\" (24 hours). extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. alpha - confidence interval width in the range (0, 1), by default it is 0.95. If None, then confidence interval is not shown. n_samples - number of bootstrap samples used to estimate confidence interval bounds (default=100). Ignored if alpha is None. axes - tuple with matplotlib Axes (ax_shape, ax_scale) for shape and scale values. If None (default), new figure and axes are created. figsize - figure size in inches in format (width, height). By default it is (8, 5). progress - if True, shows tqdm progress bar. By default False. Requires tqdm package.","title":"Parameter Stability"},{"location":"user-guide/5-threshold-selection/#return-value-stability","text":"An extension of the previous technique is to investigate stability of a target return value with a pre-defined return period over a range of thresholds. This technique provides a more intuitive metric of model stability. Let's plot it for the range of thresholds identified earlier: from pyextremes import plot_return_value_stability plot_return_value_stability ( data , return_period = 100 , thresholds = np . linspace ( 1.2 , 1.8 , 20 ), alpha = 0.95 , ) As seen in the figure above, the model is very stable for threshold values above 1.4. The plot_return_value_stability function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted return_period - return period given as a multiple of return_period_size . return_period_size - size of return period. Same as the r argument. By default this is 1 year. thresholds - array of threshold for which the plot is displayed. By default 100 equally-spaced thresholds between 90th (10th if extremes_type = \"high\" ) percentile and 10th largest (smallest if extremes_type = \"low\" ) value in the series. r - minimum time distance (window duration) between adjacent clusters. Used to decluster exceedances by locating clusters where all exceedances are separated by distances no more than r and then locating maximum or minimum (depends on extremes_type ) values within each cluster. By default r = \"24H\" (24 hours). extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. distributions - list of distributions for which the plot is produced. By default these are \"genpareto\" and \"expon\". A distribution must be either a name of distribution from scipy.stats or a subclass of scipy.stats.rv_continuous. See scipy.stats documentation alpha - confidence interval width in the range (0, 1), by default it is 0.95. If None, then confidence interval is not shown. n_samples - number of bootstrap samples used to estimate confidence interval bounds (default=100). Ignored if alpha is None. ax - matplotlib Axes object. If provided, then the plot is drawn on this axes. If None (default), new figure and axes are created figsize - figure size in inches in format (width, height). By default it is (8, 5). progress - if True, shows tqdm progress bar. By default False. Requires tqdm package. Warning This is the most dangerous threshold selection teqchnique presented in this section. It can be abused by selecting a threshold value which gives a desired result. Results of such analysis would be biased and invalid. Analyst should honestly present results of their analysis and high variance in answer should be considered a valuable result as well - it indicates that available data cann be used to obtain reliable results and that there is high uncertainty in the analyzed process.","title":"Return Value Stability"},{"location":"user-guide/5-threshold-selection/#putting-it-all-together","text":"pyextremes provides a convenience function to put all of the above together. It also adds an additional plot - AIC curve indicating relative model performance. The AIC curve should not be used as a threshold selection tool because it will always have the same logarithmic shape. Instead, it should guide the user as to which model (e.g. GEVD or Exponential) should be preferred for a given threshold. from pyextremes import plot_threshold_stability plot_threshold_stability ( data , return_period = 100 , thresholds = np . linspace ( 1.2 , 1.8 , 20 ), ) Based on the figures shown earlier, one may conclude that the valid threshold may lie between 1.4 and 1.6. A decision was made to select threshold value of 1.5. The plot_threshold_stability function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted return_period - return period given as a multiple of return_period_size . return_period_size - size of return period. Same as the r argument. By default this is 1 year. thresholds - array of threshold for which the plot is displayed. By default 100 equally-spaced thresholds between 90th (10th if extremes_type = \"high\" ) percentile and 10th largest (smallest if extremes_type = \"low\" ) value in the series. r - minimum time distance (window duration) between adjacent clusters. Used to decluster exceedances by locating clusters where all exceedances are separated by distances no more than r and then locating maximum or minimum (depends on extremes_type ) values within each cluster. By default r = \"24H\" (24 hours). extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. distributions - list of distributions for which the plot is produced. By default these are \"genpareto\" and \"expon\". A distribution must be either a name of distribution from scipy.stats or a subclass of scipy.stats.rv_continuous. See scipy.stats documentation alpha - confidence interval width in the range (0, 1), by default it is 0.95. If None, then confidence interval is not shown. n_samples - number of bootstrap samples used to estimate confidence interval bounds (default=100). Ignored if alpha is None. ax - matplotlib Axes object. If provided, then the plot is drawn on this axes. If None (default), new figure and axes are created figsize - figure size in inches in format (width, height). By default it is (8, 5). progress - if True, shows tqdm progress bar. By default False. Requires tqdm package. Results of selecting the threshold value 1.5 are shown below:","title":"Putting it all Together"},{"location":"user-guide/6-return-periods/","text":"This section demonstrates how empirical probabilities (return periods) can be obtained for extreme values extracted using methods described in earlier sections. What is Return Period \u00b6 Return period indicates duration of time (typically years) which corresponds to a probability that a given value (e.g. wind speed) would be exceeded at least once within a year. This probability is called probability of exceedance and is related to return periods as 1/p where p is return period. Coles (2001, p.49) In common terminology, \\(z_{p}\\) is the return level associated with the return period \\(1/p\\) , since to a reasonable degree of accuracy, the level \\(z_{p}\\) is expected to be exceeded on average once every \\(1/p\\) years. More precisely, \\(z_{p}\\) is exceeded by the annual maximum in any particular year with probability \\(p\\) . Return periods are often incorrectly interpreted in the professional communities as \"100-year event is an event which happens only once in 100 years\", which may lead to inaccurate assessment of risks. A more holistic way of looking at this is to consider a time period within which a risk is evaluated. For example, a 100-year event with probability of exceedance in any given year of 1% would have a probability of ~39.5% to be exceeded at least once within 50 years - this is calculated using this formula: \\[1 - (1 - p) ^ n\\] Where \\(n\\) is number of return period blocks within a time period (50 for 50 years with retun period block of size 1 year) and \\(p\\) is 1% (100-year event). Empirical Return Periods \u00b6 Empirical return periods are assigned to observed extreme values using an empricial rule where extreme values are ordered and ranked from the most extreme (1) to the least extreme (n), then exceedance probabilities are calculated (see the following sub-section), and return periods are calculated as multiples of a given return_period_size (typically 1 year). Probability of Exceedance \u00b6 Extreme events extracted using BM or POT methods are assigned exceedance probabilities using the following formula: \\[P = \\frac{r - \\alpha}{n + 1 - \\alpha - \\beta}\\] where: r - rank of extreme value (1 to n). In pyextremes rank is calculated using scipy.stats.rankdata with method = \"average\" , which means that extreme events of the same magnitude are assigned average of ranks these values would be assigned otherwise if ranked sequentially. For example, array of [1, 2, 3, 3, 4] would have ranks of [5, 4, 2.5, 2.5, 1] . n - number of extreme values. \\(\\alpha\\) and \\(\\beta\\) - empricial plotting position parameters (see further below). In this context \\(P\\) corresponds to a probability of exceedance of a value with rank r in a any given time period with duration \\(t/n\\) where \\(t\\) is total duration of series from which the extreme values were drawn and \\(n\\) is number of extreme events. If we measure time in years and we use Block Maxima with block size of 1 year, then the formula \\(t/n\\) becomes 1 by definition and the return period in years can be calculated as \\(1/P\\) . For general rule read this tutorial section further. Plotting Positions \u00b6 Plotting positions are sets of empirical coefficients defining how extreme values are assigned probabilities, which are subsequently used to plot extreme values on the probability plots. Warning Plotting positions have nothing to do with modeling extreme event statistics in modern EVA. Historically, in time before computers became widespread, EVA was performed by plotting extreme events on probability paper (with axes scaled logarithmically and according to a specific plotting position) with the idea that a return value curve for a given model (e.g. GEVD) would be a straight line drawn through these points using a pen and a ruler. Modern EVA fits models to data by maximimizng likelihood function via methods such as MLE or MCMC (read more in other sections). This is only feasible due to the use of computers and would be prohibitively expensive to do manually. Plotting positions are presently used only to show extreme values on return value plots and to perform some goodness-of-fit tests (e.g. P-P or Q-Q plots). TL;DR: plotting positions are NOT used to fit models. An example of plotting positions used in pyextremes is the diagnostic plot where observed extreme values (black dots) are superimposed against the theoretical estimates (by fitting a distribution) as seen in the return value, Q-Q, and P-P plots. Return Period \u00b6 Return periods are calculated from the exceedance probabilities using the following formula: \\[R = 1 / P / \\lambda\\] where: R - return period as multiple of return_period_size (by default 1 year). P - exceedance probability calculated earlier. \\(\\lambda\\) - rate of extreme events (average number of extreme events per return_period_size ). Calculated as: \\(\\lambda\\) = return_period_size / block_size for Block Maxima \\(\\lambda = \\frac{n}{t / return\\_period\\_size}\\) for Peaks Ove Threshold, where \\(n\\) is number of extreme events and \\(t\\) is total duration of series from which the extreme values were drawn The resulting return period R is, therefore, a real number representing a multiple of return_period_size . Example We have 2 years of data and, using block_size of 30 days (~1 month), we extract 24 extreme events using the Block Maxima method. We then rank the values from 1 to 24 as outlined above and, using the Weibull plotting position ( \\(\\alpha=0\\) and \\(\\beta=0\\) ), for the most extreme value (rank 1) we get exceedance probability \\(P\\) of 1/25 or 0.04. Let's say we would like to get return period of the most extreme value (rank 1) in years ( return_period_size of 1 year). First, we calculate extreme value rate \\(\\lambda\\) as return_period_size / block_size , which gives us 12 (approximately since we used 30 days for block_size ). Now we can use the return period formula above directly as \\(R = 1 / 0.04 / 12 = 2.08\\) years. Estimating Return Periods \u00b6 pyextremes estimates empirical return periods for many plotting functions and goodness-of-fit tests behind the scenes using the Weibull plotting position. Return periods can be calculated using the get_return_periods function (shown only for Block Maxima; Peaks Over Threshold works identically with the only difference being the block_size argument): weibull (default) from pyextremes import get_extremes , get_return_periods extremes = get_extremes ( ts = data , method = \"BM\" , block_size = \"365.2425D\" , ) return_periods = get_return_periods ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , return_period_size = \"365.2425D\" , plotting_position = \"weibull\" , ) return_periods . sort_values ( \"return period\" , ascending = False ) . head () Date-Time (GMT) Water Elevation [m NAVD88] exceedance probability return period 2012-10-30 01:00:00 3.357218 0.010526 95.000000 1960-09-12 18:00:00 2.295832 0.021053 47.500000 1992-12-11 14:00:00 2.108284 0.031579 31.666667 1953-11-07 12:00:00 2.101487 0.042105 23.750000 1950-11-25 14:00:00 2.012957 0.052632 19.000000 median from pyextremes import get_extremes , get_return_periods extremes = get_extremes ( ts = data , method = \"BM\" , block_size = \"365.2425D\" , ) return_periods = get_return_periods ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , return_period_size = \"365.2425D\" , plotting_position = \"median\" , ) return_periods . sort_values ( \"return period\" , ascending = False ) . head () Date-Time (GMT) Water Elevation [m NAVD88] exceedance probability return period 2012-10-30 01:00:00 3.357218 0.007233 138.263736 1960-09-12 18:00:00 2.295832 0.017830 56.086181 1992-12-11 14:00:00 2.108284 0.028427 35.178006 1953-11-07 12:00:00 2.101487 0.039024 25.625255 1950-11-25 14:00:00 2.012957 0.049621 20.152696 cunnane from pyextremes import get_extremes , get_return_periods extremes = get_extremes ( ts = data , method = \"BM\" , block_size = \"365.2425D\" , ) return_periods = get_return_periods ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , return_period_size = \"365.2425D\" , plotting_position = \"cunnane\" , ) return_periods . sort_values ( \"return period\" , ascending = False ) . head () Date-Time (GMT) Water Elevation [m NAVD88] exceedance probability return period 2012-10-30 01:00:00 3.357218 0.006369 157.000000 1960-09-12 18:00:00 2.295832 0.016985 58.875000 1992-12-11 14:00:00 2.108284 0.027601 36.230769 1953-11-07 12:00:00 2.101487 0.038217 26.166667 1950-11-25 14:00:00 2.012957 0.048832 20.478261 gringorten from pyextremes import get_extremes , get_return_periods extremes = get_extremes ( ts = data , method = \"BM\" , block_size = \"365.2425D\" , ) return_periods = get_return_periods ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , return_period_size = \"365.2425D\" , plotting_position = \"gringorten\" , ) return_periods . sort_values ( \"return period\" , ascending = False ) . head () Date-Time (GMT) Water Elevation [m NAVD88] exceedance probability return period 2012-10-30 01:00:00 3.357218 0.005950 168.071429 1960-09-12 18:00:00 2.295832 0.016575 60.333333 1992-12-11 14:00:00 2.108284 0.027199 36.765625 1953-11-07 12:00:00 2.101487 0.037824 26.438202 1950-11-25 14:00:00 2.012957 0.048449 20.640351 The get_return_periods function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted extremes - time series of extreme values. extremes_method - extreme value extraction method, must be \"BM\" or \"POT\" . extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. return_period_size - size of return period. Same as the r argument. By default this is 1 year. plotting_position : plotting position name, case-insensitive. Supported plotting positions: ecdf, hazen, weibull (default), tukey, blom, median, cunnane, gringorten, beard. The following paramters are used only when extremes_method = \"BM\" : block_size - block size, by default \"365.2425D\" . Internally is converted using the pandas . to_timedelta function. If not provided, then it is calculated as median distance between extreme values. Note You can get the data variable referenced above by running the following code: data = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) data = ( data . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1925\" ):] ) data = ( data - ( data . index . array - pd . to_datetime ( \"1992\" )) ) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 \"battery_wl.csv\" can be downloaded here . All figures shown in this tutorial section were generated using this jupyter notebook .","title":"Estimating Return Periods"},{"location":"user-guide/6-return-periods/#what-is-return-period","text":"Return period indicates duration of time (typically years) which corresponds to a probability that a given value (e.g. wind speed) would be exceeded at least once within a year. This probability is called probability of exceedance and is related to return periods as 1/p where p is return period. Coles (2001, p.49) In common terminology, \\(z_{p}\\) is the return level associated with the return period \\(1/p\\) , since to a reasonable degree of accuracy, the level \\(z_{p}\\) is expected to be exceeded on average once every \\(1/p\\) years. More precisely, \\(z_{p}\\) is exceeded by the annual maximum in any particular year with probability \\(p\\) . Return periods are often incorrectly interpreted in the professional communities as \"100-year event is an event which happens only once in 100 years\", which may lead to inaccurate assessment of risks. A more holistic way of looking at this is to consider a time period within which a risk is evaluated. For example, a 100-year event with probability of exceedance in any given year of 1% would have a probability of ~39.5% to be exceeded at least once within 50 years - this is calculated using this formula: \\[1 - (1 - p) ^ n\\] Where \\(n\\) is number of return period blocks within a time period (50 for 50 years with retun period block of size 1 year) and \\(p\\) is 1% (100-year event).","title":"What is Return Period"},{"location":"user-guide/6-return-periods/#empirical-return-periods","text":"Empirical return periods are assigned to observed extreme values using an empricial rule where extreme values are ordered and ranked from the most extreme (1) to the least extreme (n), then exceedance probabilities are calculated (see the following sub-section), and return periods are calculated as multiples of a given return_period_size (typically 1 year).","title":"Empirical Return Periods"},{"location":"user-guide/6-return-periods/#probability-of-exceedance","text":"Extreme events extracted using BM or POT methods are assigned exceedance probabilities using the following formula: \\[P = \\frac{r - \\alpha}{n + 1 - \\alpha - \\beta}\\] where: r - rank of extreme value (1 to n). In pyextremes rank is calculated using scipy.stats.rankdata with method = \"average\" , which means that extreme events of the same magnitude are assigned average of ranks these values would be assigned otherwise if ranked sequentially. For example, array of [1, 2, 3, 3, 4] would have ranks of [5, 4, 2.5, 2.5, 1] . n - number of extreme values. \\(\\alpha\\) and \\(\\beta\\) - empricial plotting position parameters (see further below). In this context \\(P\\) corresponds to a probability of exceedance of a value with rank r in a any given time period with duration \\(t/n\\) where \\(t\\) is total duration of series from which the extreme values were drawn and \\(n\\) is number of extreme events. If we measure time in years and we use Block Maxima with block size of 1 year, then the formula \\(t/n\\) becomes 1 by definition and the return period in years can be calculated as \\(1/P\\) . For general rule read this tutorial section further.","title":"Probability of Exceedance"},{"location":"user-guide/6-return-periods/#plotting-positions","text":"Plotting positions are sets of empirical coefficients defining how extreme values are assigned probabilities, which are subsequently used to plot extreme values on the probability plots. Warning Plotting positions have nothing to do with modeling extreme event statistics in modern EVA. Historically, in time before computers became widespread, EVA was performed by plotting extreme events on probability paper (with axes scaled logarithmically and according to a specific plotting position) with the idea that a return value curve for a given model (e.g. GEVD) would be a straight line drawn through these points using a pen and a ruler. Modern EVA fits models to data by maximimizng likelihood function via methods such as MLE or MCMC (read more in other sections). This is only feasible due to the use of computers and would be prohibitively expensive to do manually. Plotting positions are presently used only to show extreme values on return value plots and to perform some goodness-of-fit tests (e.g. P-P or Q-Q plots). TL;DR: plotting positions are NOT used to fit models. An example of plotting positions used in pyextremes is the diagnostic plot where observed extreme values (black dots) are superimposed against the theoretical estimates (by fitting a distribution) as seen in the return value, Q-Q, and P-P plots.","title":"Plotting Positions"},{"location":"user-guide/6-return-periods/#return-period","text":"Return periods are calculated from the exceedance probabilities using the following formula: \\[R = 1 / P / \\lambda\\] where: R - return period as multiple of return_period_size (by default 1 year). P - exceedance probability calculated earlier. \\(\\lambda\\) - rate of extreme events (average number of extreme events per return_period_size ). Calculated as: \\(\\lambda\\) = return_period_size / block_size for Block Maxima \\(\\lambda = \\frac{n}{t / return\\_period\\_size}\\) for Peaks Ove Threshold, where \\(n\\) is number of extreme events and \\(t\\) is total duration of series from which the extreme values were drawn The resulting return period R is, therefore, a real number representing a multiple of return_period_size . Example We have 2 years of data and, using block_size of 30 days (~1 month), we extract 24 extreme events using the Block Maxima method. We then rank the values from 1 to 24 as outlined above and, using the Weibull plotting position ( \\(\\alpha=0\\) and \\(\\beta=0\\) ), for the most extreme value (rank 1) we get exceedance probability \\(P\\) of 1/25 or 0.04. Let's say we would like to get return period of the most extreme value (rank 1) in years ( return_period_size of 1 year). First, we calculate extreme value rate \\(\\lambda\\) as return_period_size / block_size , which gives us 12 (approximately since we used 30 days for block_size ). Now we can use the return period formula above directly as \\(R = 1 / 0.04 / 12 = 2.08\\) years.","title":"Return Period"},{"location":"user-guide/6-return-periods/#estimating-return-periods","text":"pyextremes estimates empirical return periods for many plotting functions and goodness-of-fit tests behind the scenes using the Weibull plotting position. Return periods can be calculated using the get_return_periods function (shown only for Block Maxima; Peaks Over Threshold works identically with the only difference being the block_size argument): weibull (default) from pyextremes import get_extremes , get_return_periods extremes = get_extremes ( ts = data , method = \"BM\" , block_size = \"365.2425D\" , ) return_periods = get_return_periods ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , return_period_size = \"365.2425D\" , plotting_position = \"weibull\" , ) return_periods . sort_values ( \"return period\" , ascending = False ) . head () Date-Time (GMT) Water Elevation [m NAVD88] exceedance probability return period 2012-10-30 01:00:00 3.357218 0.010526 95.000000 1960-09-12 18:00:00 2.295832 0.021053 47.500000 1992-12-11 14:00:00 2.108284 0.031579 31.666667 1953-11-07 12:00:00 2.101487 0.042105 23.750000 1950-11-25 14:00:00 2.012957 0.052632 19.000000 median from pyextremes import get_extremes , get_return_periods extremes = get_extremes ( ts = data , method = \"BM\" , block_size = \"365.2425D\" , ) return_periods = get_return_periods ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , return_period_size = \"365.2425D\" , plotting_position = \"median\" , ) return_periods . sort_values ( \"return period\" , ascending = False ) . head () Date-Time (GMT) Water Elevation [m NAVD88] exceedance probability return period 2012-10-30 01:00:00 3.357218 0.007233 138.263736 1960-09-12 18:00:00 2.295832 0.017830 56.086181 1992-12-11 14:00:00 2.108284 0.028427 35.178006 1953-11-07 12:00:00 2.101487 0.039024 25.625255 1950-11-25 14:00:00 2.012957 0.049621 20.152696 cunnane from pyextremes import get_extremes , get_return_periods extremes = get_extremes ( ts = data , method = \"BM\" , block_size = \"365.2425D\" , ) return_periods = get_return_periods ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , return_period_size = \"365.2425D\" , plotting_position = \"cunnane\" , ) return_periods . sort_values ( \"return period\" , ascending = False ) . head () Date-Time (GMT) Water Elevation [m NAVD88] exceedance probability return period 2012-10-30 01:00:00 3.357218 0.006369 157.000000 1960-09-12 18:00:00 2.295832 0.016985 58.875000 1992-12-11 14:00:00 2.108284 0.027601 36.230769 1953-11-07 12:00:00 2.101487 0.038217 26.166667 1950-11-25 14:00:00 2.012957 0.048832 20.478261 gringorten from pyextremes import get_extremes , get_return_periods extremes = get_extremes ( ts = data , method = \"BM\" , block_size = \"365.2425D\" , ) return_periods = get_return_periods ( ts = data , extremes = extremes , extremes_method = \"BM\" , extremes_type = \"high\" , block_size = \"365.2425D\" , return_period_size = \"365.2425D\" , plotting_position = \"gringorten\" , ) return_periods . sort_values ( \"return period\" , ascending = False ) . head () Date-Time (GMT) Water Elevation [m NAVD88] exceedance probability return period 2012-10-30 01:00:00 3.357218 0.005950 168.071429 1960-09-12 18:00:00 2.295832 0.016575 60.333333 1992-12-11 14:00:00 2.108284 0.027199 36.765625 1953-11-07 12:00:00 2.101487 0.037824 26.438202 1950-11-25 14:00:00 2.012957 0.048449 20.640351 The get_return_periods function uses the following parameters: ts - time series ( pandas.Series ) from which the extreme values are extracted extremes - time series of extreme values. extremes_method - extreme value extraction method, must be \"BM\" or \"POT\" . extremes_type - extreme value type: \"high\" for above threshold (default) and \"low\" for below threshold. return_period_size - size of return period. Same as the r argument. By default this is 1 year. plotting_position : plotting position name, case-insensitive. Supported plotting positions: ecdf, hazen, weibull (default), tukey, blom, median, cunnane, gringorten, beard. The following paramters are used only when extremes_method = \"BM\" : block_size - block size, by default \"365.2425D\" . Internally is converted using the pandas . to_timedelta function. If not provided, then it is calculated as median distance between extreme values. Note You can get the data variable referenced above by running the following code: data = pd . read_csv ( \"battery_wl.csv\" , index_col = 0 , parse_dates = True , squeeze = True , ) data = ( data . sort_index ( ascending = True ) . astype ( float ) . dropna () . loc [ pd . to_datetime ( \"1925\" ):] ) data = ( data - ( data . index . array - pd . to_datetime ( \"1992\" )) ) / pd . to_timedelta ( \"365.2425D\" ) * 2.87e-3 \"battery_wl.csv\" can be downloaded here . All figures shown in this tutorial section were generated using this jupyter notebook .","title":"Estimating Return Periods"},{"location":"user-guide/7-models/","text":"Means MLE and MCMC, not GEVD and GPD.","title":"7 models"},{"location":"user-guide/8-mle/","text":"","title":"8 mle"},{"location":"user-guide/9-mcmc/","text":"MAP instead of MLE.","title":"9 mcmc"},{"location":"user-guide-advanced/1-distributions/","text":"Distribution class and how it works.","title":"1 distributions"},{"location":"user-guide-advanced/2-extreme-value-transformation/","text":"Block minima and peaks-below-threshold.","title":"2 extreme value transformation"}]}